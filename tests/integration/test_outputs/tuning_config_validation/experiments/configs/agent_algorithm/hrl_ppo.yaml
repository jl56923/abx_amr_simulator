# HRL PPO agent configuration
# Manager policy uses PPO over option indices.

algorithm: "HRL_PPO"

# Policy network architecture
policy_kwargs:
  net_arch:
    - 128
    - 128

# PPO hyperparameters for the manager policy
ppo:
  learning_rate: 3.0e-4
  n_steps: 256
  batch_size: 64
  n_epochs: 10
  gamma: 0.99
  gae_lambda: 0.95
  clip_range: 0.2
  ent_coef: 0.02
  vf_coef: 0.5
  max_grad_norm: 0.5
  verbose: 0
